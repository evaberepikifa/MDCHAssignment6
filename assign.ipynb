{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2      3      4    5    6      7    8    9    10   11   12  13\n",
      "0  63.0  1.0  1.0  145.0  233.0  1.0  2.0  150.0  0.0  2.3  3.0  0.0  6.0   0\n",
      "1  67.0  1.0  4.0  160.0  286.0  0.0  2.0  108.0  1.0  1.5  2.0  3.0  3.0   2\n",
      "2  67.0  1.0  4.0  120.0  229.0  0.0  2.0  129.0  1.0  2.6  2.0  2.0  7.0   1\n",
      "3  37.0  1.0  3.0  130.0  250.0  0.0  0.0  187.0  0.0  3.5  3.0  0.0  3.0   0\n",
      "4  41.0  0.0  2.0  130.0  204.0  0.0  2.0  172.0  0.0  1.4  1.0  0.0  3.0   0\n"
     ]
    }
   ],
   "source": [
    "#load dataset\n",
    "data = pd.read_csv('processed.cleveland.data', header=None)\n",
    "data.columns\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define target and variable \n",
    "X = data.drop(13, axis=1)\n",
    "y = data[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0      3      4      7    9    11\n",
      "0    63.0  145.0  233.0  150.0  2.3  0.0\n",
      "1    67.0  160.0  286.0  108.0  1.5  3.0\n",
      "2    67.0  120.0  229.0  129.0  2.6  2.0\n",
      "3    37.0  130.0  250.0  187.0  3.5  0.0\n",
      "4    41.0  130.0  204.0  172.0  1.4  0.0\n",
      "..    ...    ...    ...    ...  ...  ...\n",
      "298  45.0  110.0  264.0  132.0  1.2  0.0\n",
      "299  68.0  144.0  193.0  141.0  3.4  2.0\n",
      "300  57.0  130.0  131.0  115.0  1.2  1.0\n",
      "301  57.0  130.0  236.0  174.0  0.0  1.0\n",
      "302  38.0  138.0  175.0  173.0  0.0  NaN\n",
      "\n",
      "[303 rows x 6 columns]\n",
      "      1    2    5    6    8    10   12\n",
      "0    1.0  1.0  1.0  2.0  0.0  3.0  6.0\n",
      "1    1.0  4.0  0.0  2.0  1.0  2.0  3.0\n",
      "2    1.0  4.0  0.0  2.0  1.0  2.0  7.0\n",
      "3    1.0  3.0  0.0  0.0  0.0  3.0  3.0\n",
      "4    0.0  2.0  0.0  2.0  0.0  1.0  3.0\n",
      "..   ...  ...  ...  ...  ...  ...  ...\n",
      "298  1.0  1.0  0.0  0.0  0.0  2.0  7.0\n",
      "299  1.0  4.0  1.0  0.0  0.0  2.0  7.0\n",
      "300  1.0  4.0  0.0  0.0  1.0  2.0  7.0\n",
      "301  0.0  2.0  0.0  2.0  0.0  2.0  3.0\n",
      "302  1.0  3.0  0.0  0.0  0.0  1.0  3.0\n",
      "\n",
      "[303 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "continuous_cols= X.iloc[:, [0, 3, 4, 7, 9, 11]]\n",
    "categorical_cols = X.iloc[:, [1, 2, 5, 6, 8, 10, 12]]\n",
    "print(continuous_cols)\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.replace('?', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputers : mean and mode\n",
    "imp_cat = SimpleImputer(strategy='most_frequent')\n",
    "imp_cont = SimpleImputer(strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     False\n",
       "2     False\n",
       "5     False\n",
       "6     False\n",
       "8     False\n",
       "10    False\n",
       "12    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#impute missing values\n",
    "X_cont_imputed = pd.DataFrame(imp_cont.fit_transform(continuous_cols), columns=continuous_cols.columns)\n",
    "X_cat_imputed = pd.DataFrame(imp_cat.fit_transform(categorical_cols), columns=categorical_cols.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 1. 1. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 1. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#one hot encode categorical variable    \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(drop='first')\n",
    "ohe_cat = encoder.fit_transform(X_cat_imputed).toarray()\n",
    "print(ohe_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.94872647  0.75752504 -0.2649003   0.01719733  1.08733806 -0.72309499]\n",
      " [ 1.39200191  1.61121989  0.76041519 -1.82190531  0.39718162  2.50385129]\n",
      " [ 1.39200191 -0.6652997  -0.34228261 -0.90235399  1.34614673  1.42820253]\n",
      " ...\n",
      " [ 0.28381332 -0.0961698  -2.23814899 -1.51538821  0.13837295  0.35255377]\n",
      " [ 0.28381332 -0.0961698  -0.20686358  1.06811312 -0.89686172  0.35255377]\n",
      " [-1.82174501  0.35913411 -1.38694368  1.02432497 -0.89686172  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#scale continuous variable\n",
    "scaler = StandardScaler()\n",
    "X_cont_scaled = scaler.fit_transform(X_cont_imputed)\n",
    "print(X_cont_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected a 2-dimensional container but got <class 'pandas.core.series.Series'> instead. Pass a DataFrame containing a single row (i.e. single sample) or a single column (i.e. single feature) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m nominal_column = y\n\u001b[32m      3\u001b[39m enc = OneHotEncoder(categories=\u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df_hd_named_enc = pd.DataFrame(\u001b[43menc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m.toarray())\n\u001b[32m      6\u001b[39m df_ohe = df_hd_named_enc.columns = enc.get_feature_names_out(y)\n\u001b[32m      7\u001b[39m df_ohe.head(\u001b[32m10\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eva.berepiki\\AppData\\Local\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eva.berepiki\\AppData\\Local\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:918\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    903\u001b[39m         warnings.warn(\n\u001b[32m    904\u001b[39m             (\n\u001b[32m    905\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has a `transform`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    914\u001b[39m         )\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    920\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eva.berepiki\\AppData\\Local\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eva.berepiki\\AppData\\Local\\miniconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:991\u001b[39m, in \u001b[36mOneHotEncoder.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    972\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    973\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    974\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    975\u001b[39m \u001b[33;03m    Fit OneHotEncoder to X.\u001b[39;00m\n\u001b[32m    976\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    989\u001b[39m \u001b[33;03m        Fitted encoder.\u001b[39;00m\n\u001b[32m    990\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m991\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    992\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    993\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    994\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    995\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    996\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_drop_idx()\n\u001b[32m    997\u001b[39m     \u001b[38;5;28mself\u001b[39m._n_features_outs = \u001b[38;5;28mself\u001b[39m._compute_n_features_outs()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eva.berepiki\\AppData\\Local\\miniconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:83\u001b[39m, in \u001b[36m_BaseEncoder._fit\u001b[39m\u001b[34m(self, X, handle_unknown, ensure_all_finite, return_counts, return_and_ignore_missing_for_infrequent)\u001b[39m\n\u001b[32m     81\u001b[39m _check_n_features(\u001b[38;5;28mself\u001b[39m, X, reset=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     82\u001b[39m _check_feature_names(\u001b[38;5;28mself\u001b[39m, X, reset=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m X_list, n_samples, n_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_X\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;28mself\u001b[39m.n_features_in_ = n_features\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.categories != \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eva.berepiki\\AppData\\Local\\miniconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:49\u001b[39m, in \u001b[36m_BaseEncoder._check_X\u001b[39m\u001b[34m(self, X, ensure_all_finite)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[33;03mPerform custom check_array:\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[33;03m- convert list of strings to object dtype\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m \n\u001b[32m     46\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(X, \u001b[33m\"\u001b[39m\u001b[33miloc\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(X, \u001b[33m\"\u001b[39m\u001b[33mndim\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0\u001b[39m) == \u001b[32m2\u001b[39m):\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# if not a dataframe, do normal check_array validation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     X_temp = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m np.issubdtype(X_temp.dtype, np.str_):\n\u001b[32m     51\u001b[39m         X = check_array(X, dtype=\u001b[38;5;28mobject\u001b[39m, ensure_all_finite=ensure_all_finite)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eva.berepiki\\AppData\\Local\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1093\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1086\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1087\u001b[39m             msg = (\n\u001b[32m   1088\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1089\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1090\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1091\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mif it contains a single sample.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1092\u001b[39m             )\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1095\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array.dtype, \u001b[33m\"\u001b[39m\u001b[33mkind\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array.dtype.kind \u001b[38;5;129;01min\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mUSV\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1096\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1097\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdtype=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mnumeric\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1098\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1099\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Expected a 2-dimensional container but got <class 'pandas.core.series.Series'> instead. Pass a DataFrame containing a single row (i.e. single sample) or a single column (i.e. single feature) instead."
     ]
    }
   ],
   "source": [
    "#ohe target variable\n",
    "nominal_column = y\n",
    "enc = OneHotEncoder(categories='auto')\n",
    "df_hd_named_enc = pd.DataFrame(enc.fit_transform(\n",
    "    y).toarray())\n",
    "df_ohe = df_hd_named_enc.columns = enc.get_feature_names_out(y)\n",
    "df_ohe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
